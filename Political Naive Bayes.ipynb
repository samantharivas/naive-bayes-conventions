{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details. You can download the required DB from the shared dropbox or from blackboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "import string \n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Feel free to include your text patterns functions\n",
    "#from text_functions_solutions import clean_tokenize, get_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/samantharivas/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/samantharivas/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# define function to clean and tokenize text\n",
    "def clean_tokenize(text):\n",
    "    #tokenize text \n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    #convert to lowercase\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    \n",
    "    #remove punctuations \n",
    "    tokens = [word for word in tokens if word not in string.punctuation]\n",
    "    \n",
    "    #remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# define function to clean and tokenize tweets\n",
    "def clean_tokenize_tweet(text):\n",
    "    text = text.decode('utf-8')  \n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word.lower() for word in tokens if word.isalpha()]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "# define function to convert textt to feature dictionary\n",
    "def conv_features(text, fw):\n",
    "    words = text.split()\n",
    "    ret_dict = {word: True for word in words if word in fw}\n",
    "    return ret_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(\"2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conventions\n"
     ]
    }
   ],
   "source": [
    "convention_cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "\n",
    "# retrieve table names \n",
    "tables = convention_cur.fetchall()\n",
    "for table in tables:\n",
    "    print(table[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text \n",
    "for each party and prepare it for use in Naive Bayes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_data = []\n",
    "\n",
    "# fill this list up with items that are themselves lists. The \n",
    "# first element in the sublist should be the cleaned and tokenized\n",
    "# text in a single string. As part of your cleaning process,\n",
    "# remove the stopwords from the text. The second element of the sublist\n",
    "# should be the party. \n",
    "\n",
    "query_results = convention_cur.execute(\n",
    "                            '''\n",
    "                            SELECT text, party FROM conventions\n",
    "                            ''')\n",
    "\n",
    "for row in query_results :\n",
    "    text = row[0]\n",
    "    party = row[1]\n",
    "    \n",
    "    #clean, tokenize, remove stopwords\n",
    "    cleaned_text = clean_tokenize(text)\n",
    "    cleaned_text = [word for word in cleaned_text if word not in stop_words]\n",
    "    \n",
    "    convention_data.append([cleaned_text, party])\n",
    "    \n",
    "convention_db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['top',\n",
       "   'consider',\n",
       "   'marxist',\n",
       "   'liberal',\n",
       "   'activist',\n",
       "   'leading',\n",
       "   'mob',\n",
       "   'neighborhood',\n",
       "   'stood',\n",
       "   'outside',\n",
       "   'home',\n",
       "   'bull',\n",
       "   'horn',\n",
       "   'screaming',\n",
       "   '“',\n",
       "   '’',\n",
       "   'stop',\n",
       "   'revolution.',\n",
       "   '”',\n",
       "   'weeks',\n",
       "   'later',\n",
       "   'marxist',\n",
       "   'activist',\n",
       "   'democrat',\n",
       "   'nomination',\n",
       "   'hold',\n",
       "   'seat',\n",
       "   'us',\n",
       "   'house',\n",
       "   'representatives',\n",
       "   'city',\n",
       "   'st.',\n",
       "   'louis',\n",
       "   '’',\n",
       "   'winning',\n",
       "   'general',\n",
       "   'election',\n",
       "   'marxist',\n",
       "   'revolutionary',\n",
       "   'going',\n",
       "   'congresswoman',\n",
       "   'first',\n",
       "   'district',\n",
       "   'missouri',\n",
       "   'radicals',\n",
       "   'content',\n",
       "   'marching',\n",
       "   'streets',\n",
       "   'want',\n",
       "   'walk',\n",
       "   'halls',\n",
       "   'congress',\n",
       "   'want',\n",
       "   'take',\n",
       "   'want',\n",
       "   'power',\n",
       "   'joe',\n",
       "   'biden',\n",
       "   '’',\n",
       "   'party',\n",
       "   'people',\n",
       "   'charge',\n",
       "   'future',\n",
       "   'future',\n",
       "   'children'],\n",
       "  'Republican'],\n",
       " [['singing'], 'Democratic'],\n",
       " [['massachusetts'], 'Republican'],\n",
       " [['jon',\n",
       "   'honor',\n",
       "   'devotion',\n",
       "   'showing',\n",
       "   'returning',\n",
       "   'citizens',\n",
       "   'forgotten',\n",
       "   'believe',\n",
       "   'person',\n",
       "   'made',\n",
       "   'god',\n",
       "   'purpose',\n",
       "   'continue',\n",
       "   'give',\n",
       "   'americans',\n",
       "   'including',\n",
       "   'former',\n",
       "   'inmates',\n",
       "   'best',\n",
       "   'chance',\n",
       "   'build',\n",
       "   'new',\n",
       "   'life',\n",
       "   'achieve',\n",
       "   'american',\n",
       "   'dream',\n",
       "   'great',\n",
       "   'american',\n",
       "   'dream',\n",
       "   '’',\n",
       "   'like',\n",
       "   'ask',\n",
       "   'john',\n",
       "   'richard',\n",
       "   'say',\n",
       "   'words'],\n",
       "  'Republican'],\n",
       " [['family',\n",
       "   'stopped',\n",
       "   'ranching',\n",
       "   'seven',\n",
       "   'years',\n",
       "   'ago',\n",
       "   'regulations',\n",
       "   'became',\n",
       "   'overbearing',\n",
       "   'ranch',\n",
       "   'slowly',\n",
       "   'sold'],\n",
       "  'Republican']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least `word_cutoff` times. Here's the code to test that if you want it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 2330 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in convention_data for w in t] #'.split()' removed \n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text,fw) :\n",
    "    \"\"\"Given some text, this returns a dictionary holding the\n",
    "       feature words.\n",
    "       \n",
    "       Args: \n",
    "            * text: a piece of text in a continuous string. Assumes\n",
    "            text has been cleaned and case folded.\n",
    "            * fw: the *feature words* that we're considering. A word \n",
    "            in `text` must be in fw in order to be returned. This \n",
    "            prevents us from considering very rarely occurring words.\n",
    "        \n",
    "       Returns: \n",
    "            A dictionary with the words in `text` that appear in `fw`. \n",
    "            Words are only counted once. \n",
    "            If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
    "            then this would return a dictionary of \n",
    "            {'quick' : True,\n",
    "             'fox' :    True}\n",
    "        \n",
    "    \"\"\"\n",
    "    # split text into words\n",
    "    words = text.split()\n",
    "    # initialize empty directory for feature words\n",
    "    ret_dict = {}\n",
    "    # iterate through each word in text\n",
    "    for word in words: \n",
    "        #check word in set of features\n",
    "        if word in fw:\n",
    "            ret_dict[word] = True # add word to dict\n",
    "    return ret_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(feature_words)>0)\n",
    "assert(conv_features(\"donald is the president\",feature_words)==\n",
    "       {'donald':True,'president':True})\n",
    "assert(conv_features(\"some people in america are citizens\",feature_words)==\n",
    "                     {'people':True,'america':True,\"citizens\":True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(\"\".join(text),feature_words), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier accuracy on text data: 0.622\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "accuracy = nltk.classify.accuracy(classifier, test_set)\n",
    "\n",
    "print(f\"Classifier accuracy on text data: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   thank = True           Republ : Democr =      4.7 : 1.0\n",
      "                     yes = True           Democr : Republ =      2.8 : 1.0\n",
      "              california = True           Republ : Democr =      1.6 : 1.0\n",
      "                colorado = True           Republ : Democr =      1.6 : 1.0\n",
      "                 georgia = True           Republ : Democr =      1.6 : 1.0\n",
      "                    good = True           Republ : Democr =      1.6 : 1.0\n",
      "                 indiana = True           Republ : Democr =      1.6 : 1.0\n",
      "                    iowa = True           Republ : Democr =      1.6 : 1.0\n",
      "                kentucky = True           Republ : Democr =      1.6 : 1.0\n",
      "               louisiana = True           Republ : Democr =      1.6 : 1.0\n",
      "                   maine = True           Republ : Democr =      1.6 : 1.0\n",
      "             mississippi = True           Republ : Democr =      1.6 : 1.0\n",
      "                missouri = True           Republ : Democr =      1.6 : 1.0\n",
      "                 montana = True           Republ : Democr =      1.6 : 1.0\n",
      "                    ohio = True           Republ : Democr =      1.6 : 1.0\n",
      "            pennsylvania = True           Republ : Democr =      1.6 : 1.0\n",
      "               tennessee = True           Republ : Democr =      1.6 : 1.0\n",
      "                   texas = True           Republ : Democr =      1.6 : 1.0\n",
      "                    utah = True           Republ : Democr =      1.6 : 1.0\n",
      "                 vermont = True           Republ : Democr =      1.6 : 1.0\n",
      "                virginia = True           Republ : Democr =      1.6 : 1.0\n",
      "              washington = True           Republ : Democr =      1.6 : 1.0\n",
      "               wisconsin = True           Republ : Democr =      1.6 : 1.0\n",
      "                delaware = True           Democr : Republ =      1.1 : 1.0\n",
      "                 singing = None           Republ : Democr =      1.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "### My Observations\n",
    "\n",
    "From the classifier, several observations can be made. For instance, the word 'thank' appears more often in Republican texts compared to Democratic texts (displayed by the 4.7:1.0 ratio). From this, it can be concluded that Republican speeches express greater gratitude than Democratic speeches. It can also be noted that some states, such as California, Colorado, and Georgia, are labeled as informative features, indicating that references to certain states are more prevalent in speeches than others. An interesting word that appears is 'singing,' which might allude to a difference in tone or style of communication between the two parties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = []\n",
    "\n",
    "# prepare tweet data \n",
    "for row in results:\n",
    "    candidate, party, tweet_text = row\n",
    "    cleaned_text = clean_tokenize_tweet(tweet_text)\n",
    "    tweet_data.append([cleaned_text, party])\n",
    "\n",
    "# Now fill up tweet_data with sublists like we did on the convention speeches.\n",
    "# Note that this may take a bit of time, since we have a lot of tweets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use naive bayes classifier trained on convention speeches to classify the tweets\n",
    "tweet_featuresets = [(conv_features(\" \".join(text), feature_words), party) for (text, party) in tweet_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier accuracy on tweet data: 0.452\n"
     ]
    }
   ],
   "source": [
    "test_size = 500\n",
    "test_tweet_set, train_tweet_set = tweet_featuresets[:test_size], tweet_featuresets[test_size:]\n",
    "\n",
    "\n",
    "tweet_classifier = nltk.NaiveBayesClassifier.train(train_tweet_set)\n",
    "tweet_accuracy = nltk.classify.accuracy(tweet_classifier, test_tweet_set)\n",
    "\n",
    "print(f\"Classifier accuracy on tweet data: {tweet_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "              indigenous = True           Democr : Republ =     43.6 : 1.0\n",
      "             indivisible = True           Democr : Republ =     34.1 : 1.0\n",
      "            corporations = True           Democr : Republ =     33.7 : 1.0\n",
      "                equality = True           Democr : Republ =     25.0 : 1.0\n",
      "                  unborn = True           Republ : Democr =     24.4 : 1.0\n",
      "                    womb = True           Republ : Democr =     18.7 : 1.0\n",
      "                   hbcus = True           Democr : Republ =     16.2 : 1.0\n",
      "              inequality = True           Democr : Republ =     16.1 : 1.0\n",
      "               childcare = True           Democr : Republ =     15.9 : 1.0\n",
      "                  gender = True           Democr : Republ =     13.5 : 1.0\n",
      "                 vermont = True           Democr : Republ =     12.7 : 1.0\n",
      "               communism = True           Republ : Democr =     11.5 : 1.0\n",
      "                  racial = True           Democr : Republ =     10.9 : 1.0\n",
      "                 marched = True           Democr : Republ =     10.9 : 1.0\n",
      "                  planet = True           Democr : Republ =     10.6 : 1.0\n",
      "                 empathy = True           Democr : Republ =     10.4 : 1.0\n",
      "                  pelosi = True           Republ : Democr =     10.3 : 1.0\n",
      "            marginalized = True           Democr : Republ =     10.0 : 1.0\n",
      "                    lord = True           Republ : Democr =      9.9 : 1.0\n",
      "                 liberal = True           Republ : Democr =      9.3 : 1.0\n",
      "                    beto = True           Democr : Republ =      9.3 : 1.0\n",
      "                   equal = True           Democr : Republ =      8.7 : 1.0\n",
      "                  digest = True           Republ : Democr =      8.4 : 1.0\n",
      "                 decency = True           Democr : Republ =      8.4 : 1.0\n",
      "               baltimore = True           Democr : Republ =      8.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "tweet_classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: ['earlier', 'today', 'spoke', 'house', 'floor', 'abt', 'protecting', 'health', 'care', 'women', 'praised', 'ppmarmonte', 'work', 'central', 'coast', 'https']\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: ['go', 'tribe', 'rallytogether', 'https']\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: ['apparently', 'trump', 'thinks', 'easy', 'students', 'overwhelmed', 'crushing', 'burden', 'debt', 'pay', 'student', 'loans', 'trumpbudget', 'https']\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: ['grateful', 'first', 'responders', 'rescue', 'personnel', 'firefighters', 'police', 'volunteers', 'working', 'tirelessly', 'keep', 'people', 'safe', 'provide', 'help', 'putting', 'lives', 'line', 'https']\n",
      "Actual party is Republican and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: ['let', 'make', 'even', 'greater', 'kag', 'https']\n",
      "Actual party is Republican and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: ['cavs', 'tie', 'series', 'repbarbaralee', 'scared', 'roadtovictory']\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: ['congrats', 'belliottsd', 'new', 'gig', 'sd', 'city', 'hall', 'glad', 'continue', 'https']\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: ['really', 'close', 'raised', 'toward', 'match', 'right', 'whoot', 'majors', 'room', 'help', 'us', 'get', 'https', 'https']\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: ['today', 'comment', 'period', 'potus', 'plan', 'expand', 'offshore', 'drilling', 'opened', 'public', 'days', 'march', 'share', 'oppose', 'proposed', 'program', 'directly', 'trump', 'administration', 'comments', 'made', 'email', 'mail', 'https']\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: ['celebrated', 'icseastla', 'years', 'eastside', 'commitment', 'amp', 'saluted', 'community', 'leaders', 'last', 'night', 'awards', 'dinner', 'https']\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tweet, party in tweet_data_sample :\n",
    "    tweet_features = conv_features(\" \".join(tweet), feature_words)\n",
    "    estimated_party = tweet_classifier.classify(tweet_features)\n",
    "    # Fill in the right-hand side above with code that estimates the actual party\n",
    "    \n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of counts by actual party and estimated party. \n",
    "# first key is actual, second is estimated\n",
    "parties = ['Republican','Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties :\n",
    "    for p1 in parties :\n",
    "        results[p][p1] = 0\n",
    "\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(tweet_data) :\n",
    "    tweet, party = tp    \n",
    "    \n",
    "    # convert tweets to feature dictionary \n",
    "    tweet_features = conv_features(\" \".join(tweet), feature_words)\n",
    "    # get estiamated party \n",
    "    estimated_party = tweet_classifier.classify(tweet_features)\n",
    "    \n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx > num_to_score : \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'Republican': defaultdict(int,\n",
       "                         {'Republican': 1203, 'Democratic': 3169}),\n",
       "             'Democratic': defaultdict(int,\n",
       "                         {'Republican': 520, 'Democratic': 5110})})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "From the classifier, several observations can be made. The accuracy on tweet data is 0.452, slightly better than random guessing, with a noticeable bias towards predicting tweets as Democratic. This suggests that the classifier struggles with the informal and brief nature of tweets. Informative features such as 'indigenous,' 'indivisible,' and 'equality' appear more often in Democratic tweets, while 'unborn,' 'womb,' and 'lord' are more common in Republican tweets. These distinctions highlight the specific issues and terminologies each party emphasizes. The findings underscore the importance of context-specific feature engineering. To improve accuracy and generalization, incorporating additional linguistic features and using advanced NLP techniques could be beneficial."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
